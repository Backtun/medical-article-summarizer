# Configuración de API de Chutes AI
# Obtén tu API key en https://chutes.ai/
CHUTES_API_KEY=tu_api_key_de_chutes_aqui

# Modelo a usar para procesamiento de IA
# Ejemplos: zai-org/GLM-4.7-TEE, deepseek-ai/DeepSeek-V3-0324
MODEL=zai-org/GLM-4.7-TEE

# Configuración del Servidor
PORT=3001
NODE_ENV=development

# Opcional: URL del sitio para tracking
SITE_URL=http://localhost:5173
SITE_NAME=Medical Summarizer

# Opcional: URL del cliente para CORS (por defecto usa SITE_URL)
CLIENT_URL=http://localhost:5173

# ============================================
# Configuración de Seguridad y Límites
# ============================================

# Máximo de páginas a procesar (prevenir abuso)
MAX_PAGES=100

# Timeout de parsing en milisegundos (60 segundos por defecto)
PARSING_TIMEOUT_MS=60000

# ============================================
# Flags de Funcionalidades
# ============================================

# Usar prompts anti-alucinación v2 (establecer 'true' para habilitar)
USE_PROMPTS_V2=false

# ============================================
# Configuración de LLM Local (Ollama)
# ============================================

# Usar Ollama en lugar de OpenRouter (establecer 'true' para habilitar)
USE_OLLAMA=false

# URL del servidor Ollama (por defecto: http://localhost:11434)
OLLAMA_URL=http://localhost:11434

# Modelo de Ollama a usar (por defecto: GLM-4.7)
# Ejecuta 'ollama list' para ver modelos disponibles
OLLAMA_MODEL=GLM-4.7
