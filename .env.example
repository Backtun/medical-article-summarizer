# Chutes AI API Configuration
# Get your API key from https://chutes.ai/
CHUTES_API_KEY=your_chutes_api_key_here

# Model to use for AI processing
# Examples: zai-org/GLM-4.7-TEE, deepseek-ai/DeepSeek-V3-0324
MODEL=zai-org/GLM-4.7-TEE

# Server Configuration
PORT=3001
NODE_ENV=development

# Optional: Custom site URL for tracking
SITE_URL=http://localhost:5173
SITE_NAME=Medical Summarizer

# Optional: Client URL for CORS (defaults to SITE_URL)
CLIENT_URL=http://localhost:5173

# ============================================
# Security & Limits Configuration
# ============================================

# Maximum pages to process (prevent abuse)
MAX_PAGES=100

# Parsing timeout in milliseconds (60 seconds default)
PARSING_TIMEOUT_MS=60000

# ============================================
# Feature Flags
# ============================================

# Use anti-hallucination prompts v2 (set to 'true' to enable)
USE_PROMPTS_V2=false

# ============================================
# Local LLM (Ollama) Configuration
# ============================================

# Use Ollama instead of OpenRouter (set to 'true' to enable)
USE_OLLAMA=false

# Ollama server URL (default: http://localhost:11434)
OLLAMA_URL=http://localhost:11434

# Ollama model to use (default: GLM-4.7)
# Run 'ollama list' to see available models
OLLAMA_MODEL=GLM-4.7


