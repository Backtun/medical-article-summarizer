/**
 * AI Service - OpenRouter Integration
 *
 * Este servicio encapsula toda la l√≥gica de comunicaci√≥n con OpenRouter.
 * Implementa el patr√≥n de agnosticismo de modelo permitiendo cambiar
 * entre GPT-4o, Claude, Llama, etc. solo modificando variables de entorno.
 */

import OpenAI from 'openai';
import dotenv from 'dotenv';
import { PAGE_ANALYSIS_PROMPT, SUMMARY_GENERATION_PROMPT } from '../utils/prompts.js';

dotenv.config({ path: '../.env' });

// Configuraci√≥n del cliente OpenRouter
const client = new OpenAI({
  baseURL: 'https://openrouter.ai/api/v1',
  apiKey: process.env.OPENAI_API_KEY,
  defaultHeaders: {
    'HTTP-Referer': process.env.SITE_URL || 'http://localhost:5173',
    'X-Title': process.env.SITE_NAME || 'Medical Summarizer',
  },
});

/**
 * Env√≠a un an√°lisis de p√°gina a la IA
 * @param {string} pageText - Texto extra√≠do de la p√°gina
 * @param {number} pageNumber - N√∫mero de p√°gina
 * @param {Function} onLog - Callback para logs de progreso
 * @returns {Promise<string>} - An√°lisis de la p√°gina
 */
export async function analyzePage(pageText, pageNumber, onLog) {
  const model = process.env.MODEL || 'openai/gpt-5-mini';

  try {
    onLog({
      type: 'log',
      text: `ü§ñ Analyzing page ${pageNumber} with ${model}...`,
      color: 'cyan'
    });

    const response = await client.chat.completions.create({
      model: model,
      messages: [
        {
          role: 'system',
          content: PAGE_ANALYSIS_PROMPT
        },
        {
          role: 'user',
          content: `=== P√ÅGINA ${pageNumber} ===\n\n${pageText}`
        }
      ],
      temperature: 0.3,
      max_tokens: 4000,
    });

    const analysis = response.choices[0].message.content;

    onLog({
      type: 'log',
      text: `‚úì Page ${pageNumber} analyzed (${analysis.length} chars)`,
      color: 'green'
    });

    return analysis;
  } catch (error) {
    onLog({
      type: 'log',
      text: `‚úó Error analyzing page ${pageNumber}: ${error.message}`,
      color: 'red'
    });
    throw error;
  }
}

/**
 * Genera el resumen final en formato IMRyD
 * @param {string} title - T√≠tulo del documento
 * @param {Array} analyzedPages - Array de objetos { pageNumber, analysis, text }
 * @param {Function} onLog - Callback para logs de progreso
 * @returns {Promise<string>} - Resumen estructurado en Markdown
 */
export async function generateSummary(title, analyzedPages, onLog) {
  const model = process.env.MODEL || 'openai/gpt-5-mini';

  try {
    onLog({
      type: 'log',
      text: 'üìù Generating structured summary (IMRyD format)...',
      color: 'yellow'
    });

    // Combinar an√°lisis de p√°ginas - extraer la propiedad .analysis de cada objeto
    const combinedAnalysis = analyzedPages
      .map(page => `--- P√ÅGINA ${page.pageNumber} ---\n${page.analysis}`)
      .join('\n\n');

    // Tambi√©n incluir texto original como referencia
    const combinedText = analyzedPages
      .map(page => `=== P√ÅGINA ${page.pageNumber} ===\n${page.text}`)
      .join('\n\n---\n\n');

    const response = await client.chat.completions.create({
      model: model,
      messages: [
        {
          role: 'system',
          content: SUMMARY_GENERATION_PROMPT.replace('{title}', title)
        },
        {
          role: 'user',
          content: `=== AN√ÅLISIS DEL DOCUMENTO ===\n\n${combinedAnalysis}\n\n\n=== TEXTO ORIGINAL DEL DOCUMENTO ===\n\n${combinedText.substring(0, 15000)}`
        }
      ],
      temperature: 0.5,
      max_tokens: 8000,
    });

    const summary = response.choices[0].message.content;

    onLog({
      type: 'log',
      text: `‚úì Summary generated (${summary.length} chars)`,
      color: 'green'
    });

    return summary;
  } catch (error) {
    onLog({
      type: 'log',
      text: `‚úó Error generating summary: ${error.message}`,
      color: 'red'
    });
    throw error;
  }
}

export default {
  analyzePage,
  generateSummary
};
